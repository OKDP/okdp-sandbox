apiVersion: v1alpha1
name: jupyterhub
tag: 4.3.1-p01
protected: false
description: |
  JupyterHub - Multi-user interactive development environment for data science and machine learning.
  Provides secure, scalable Jupyter notebook access with integrated authentication, resource management,
  and pre-configured Spark-enabled notebooks for big data analytics.
usage:
  text: |
    JupyterHub provides multi-user Jupyter notebook environment with OAuth authentication.
    Access the hub at {{ .Context.jupyter.endpoint.url | replace "{{ .Release.namespace }}" .Release.spec.targetNamespace | replace "{{ .Release.metadata.name }}" .Release.metadata.name | replace "{{ .Context.ingress.suffix }}" .Context.ingress.suffix }}
schema:
  parameters:
    properties:
      cloneExamples: { type: boolean, default: true, description: "Whether to clone OKDP examples" }
      bucket: { type: string, default: "okdp", description: "S3 bucket name to expose in the Jupyter S3 browser" }
      sparkEventsLogDir: { type: string, required: true, default: "s3a://spark-events/event-logs/", description: "S3 path for Spark event logs, typically s3a://<bucket>/eventLogs" }
      startTimeout: { type: integer, default: 600, description: "Maximum number of seconds JupyterHub will wait for a userâ€™s server to become reachable" }
      allowedRoles: { type: string, default: "admins", description: "Allowed roles for JupyterHub access" }
      memoryGi: { type: number, default: 1, multipleOf: 0.25, description: "Notebook (singleuser) pod memory (GiB) for requests/limits." }
      cpu:      { type: number, default: 0.5, multipleOf: 0.25, description: "Notebook (singleuser) pod CPU (vCPU) for requests/limits." }
  context:
    properties:
      certificateIssuers:
        required: true
        properties:
          selfSigned:
            properties:
              name: { type: string, required: true }
      ingress:
        required: true
        properties:
          suffix: { type: string, required: true }
      storageClass:
        required: true
        properties:
          workspace: { type: string, required: true }
modules:
  - name: spark-rbac
    timeout: 10m
    source:
      local:
        path: ../spark-rbac/chart
    values: |
      rbac:
        create: {{ .Context.sparkRBAC.rbac.create }}
      serviceAccount:
        create: {{ .Context.sparkRBAC.serviceAccount.create }}
        name: "{{ .Context.sparkRBAC.serviceAccount.name }}"
        automountServiceAccountToken: {{ .Context.sparkRBAC.serviceAccount.automountServiceAccountToken }}

  - name: main
    dependsOn:
      - spark-rbac
    timeout: 10m
    source:
      helmRepository:
        url: https://hub.jupyter.org/helm-chart/
        chart: jupyterhub
        version: 4.3.1
    values: |
      {{- $s3ApiUrl := .Context.jupyter.storage.s3.apiUrl | replace "{{ .Release.namespace }}" .Release.spec.targetNamespace -}}
      {{- $s3ApiUrl := $s3ApiUrl | replace "{{ .Release.metadata.name }}" .Release.metadata.name -}}
      {{- $s3ApiUrl := $s3ApiUrl | replace "{{ .Context.ingress.suffix }}" .Context.ingress.suffix -}}
      
      {{- $jupyterUrl := .Context.jupyter.endpoint.url | replace "{{ .Release.namespace }}" .Release.spec.targetNamespace -}}
      {{- $jupyterUrl := $jupyterUrl | replace "{{ .Release.metadata.name }}" .Release.metadata.name -}}
      {{- $jupyterUrl := $jupyterUrl | replace "{{ .Context.ingress.suffix }}" .Context.ingress.suffix -}}
      {{- $jupyterHost := regexReplaceAll "^https?://" $jupyterUrl "" -}}
      
      {{- $keycloakAuthUrl := .Context.jupyter.auth.oidc.baseUrl | replace "{{ .Release.namespace }}" .Release.spec.targetNamespace -}}
      {{- $keycloakAuthUrl := $keycloakAuthUrl | replace "{{ .Release.metadata.name }}" .Release.metadata.name -}}
      {{- $keycloakAuthUrl := $keycloakAuthUrl | replace "{{ .Context.ingress.suffix }}" .Context.ingress.suffix -}}
  
      # Fix resource naming conflicts by using release name as prefix
      fullnameOverride: "{{ .Release.metadata.name }}"
      nameOverride: "{{ .Release.metadata.name }}"
      
      hub:
        extraEnv:
          OAUTH_CLIENT_ID:
            valueFrom:
              secretKeyRef:
                name: {{ .Context.jupyter.auth.oidc.credentialsSecret.name }}
                key: {{ .Context.jupyter.auth.oidc.credentialsSecret.clientIdKey }}
          OAUTH_CLIENT_SECRET:
            valueFrom:
              secretKeyRef:
                name: {{ .Context.jupyter.auth.oidc.credentialsSecret.name }}
                key: {{ .Context.jupyter.auth.oidc.credentialsSecret.clientSecretKey }}
        config:
          Authenticator:
            auto_login: true
          GenericOAuthenticator:
            oauth_callback_url: {{ $jupyterUrl }}/hub/oauth_callback
            authorize_url: {{ $keycloakAuthUrl }}/auth
            token_url: {{ $keycloakAuthUrl }}/token
            userdata_url: {{ $keycloakAuthUrl }}/userinfo
            validate_server_cert: false
            login_service: keycloak
            claim_groups_key: groups
            manage_groups: true
            userdata_params:
              state: state
            admin_groups:
              - "{{ .Parameters.allowedRoles }}"
            allowed_groups:
              - "{{ .Parameters.allowedRoles }}"
            username_key: preferred_username
            scope:
            - openid
            - groups
          JupyterHub:
            authenticator_class: generic-oauth
        networkPolicy:
          enabled: false
        extraConfig:
          extraConfig01.py: |
            c.KubeSpawner.delete_grace_period = 120
            c.ServerApp.allow_root = True
        image:
          pullPolicy: Always
          pullSecrets: []
          name: quay.io/jupyterhub/k8s-hub
          tag: "4.3.1"
        db:
          type: sqlite-pvc
          pvc:
            storage: 1Gi
            storageClassName: "{{ .Context.storageClass.workspace }}"
      
      rbac:
        create: true
      
      cull:
        enabled: false
      
      proxy:
        service:
          type: ClusterIP
      
      ingress:
        enabled: true
        annotations:
          nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
          cert-manager.io/cluster-issuer: "{{ .Context.certificateIssuers.selfSigned.name }}"
        ingressClassName: nginx
        hosts:
          - {{ $jupyterHost }}
        tls:
          - secretName: {{ .Release.metadata.name }}-tls
            hosts:
              - {{ $jupyterHost }}
      
      scheduling:
        userScheduler:
          enabled: false
        userPlaceholder:
          enabled: false
      
      singleuser:            
        # Fix user pod naming conflicts by prefixing with release name
        podNameTemplate: "{{ .Release.metadata.name }}-{username}{servername}"
        
        image:
          name: quay.io/okdp/jupyter/all-spark-notebook
          tag: "spark-3.5.6-python-3.11-java-17-scala-2.12"
        
        startTimeout: {{ .Parameters.startTimeout }}
      
        extraEnv:
          NB_USER: "$(JUPYTERHUB_USER)"
          NB_UID: "1001"
          NB_GID: "100"
          CHOWN_HOME: "yes"
          CHOWN_HOME_OPTS: "-R"
          JUPYTER_ENABLE_LAB: "yes"
          EDITOR: "vim"
          GIT_SSL_NO_VERIFY: "false"
          # Ignore InsecureRequestWarning warnings
          PYTHONWARNINGS: "ignore:Unverified HTTPS request"
      
          # https://github.com/jpmorganchase/jupyter-fs
          FS_S3_ENDPOINT_URL: "{{ $s3ApiUrl }}"
          FS_S3_ACCESS_KEY:
            valueFrom:
              secretKeyRef:
                name: "{{ .Context.jupyter.storage.s3.credentialsSecret.name }}"
                key: "{{ .Context.jupyter.storage.s3.credentialsSecret.accessKeyKey }}"
          FS_S3_SECRET_KEY:
            valueFrom:
              secretKeyRef:
                name: "{{ .Context.jupyter.storage.s3.credentialsSecret.name }}"
                key: "{{ .Context.jupyter.storage.s3.credentialsSecret.secretKeyKey }}"
          
          # Notebook pod IP used by Spark driver (spark.driver.host) in client mode
          POD_IP:
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
      
          {{- if .Context.proxy.httpProxy }}
          HTTP_PROXY: {{ .Context.proxy.httpProxy | quote }}
          {{- end }}
          {{- if .Context.proxy.httpsProxy }}
          HTTPS_PROXY: {{ .Context.proxy.httpsProxy | quote }}
          {{- end }}
          {{- if .Context.proxy.noProxy }}
          NO_PROXY: {{ .Context.proxy.noProxy | quote }}
          {{- end }}
      
        {{- if .Parameters.cloneExamples }}
        lifecycleHooks:
          postStart:
            exec:
              command:
                - /bin/bash
                - -lc
                - |
                  set -e
                  HOME="/home/$JUPYTERHUB_USER"
                  if [ ! -f "$HOME/Welcome.ipynb" ]; then
                    cp /etc/jupyterhub/welcome/Welcome.ipynb "$HOME/Welcome.ipynb"
                  fi
       
        defaultUrl: "/lab/tree/Welcome.ipynb"
        {{- end }}
      
        extraFiles:
          {{- if .Parameters.cloneExamples }}
          welcome-notebook:
            mountPath: /etc/jupyterhub/welcome/Welcome.ipynb
            stringData: |
              {
                "cells": [
                  {
                    "cell_type": "markdown",
                    "id": "127ae6f0",
                    "metadata": {},
                    "source": [
                      "# ðŸ‘‹ Welcome to OKDP Examples\n",
                      "\n",
                      "This workspace contains hands-on examples and ready-to-run workflows for the **[Open Kubernetes Data Platform (OKDP)](https://okdp.io)**.\n",
                      "\n",
                      "Youâ€™ll be able to explore:\n",
                      "\n",
                      "- **[MinIO](https://www.min.io/)** for S3-compatible object storage\n",
                      "- **[Hive Metastore](https://hive.apache.org/)** for table/catalog metadata\n",
                      "- **[Trino](https://trino.io/)** for interactive SQL queries\n",
                      "- **[Jupyter](https://jupyter.org/)** for notebooks and analysis\n",
                      "- **[Apache Superset](https://superset.apache.org/)** for dashboards and visualizations\n",
                      "\n",
                      "---\n",
                      "\n",
                      "## ðŸš€ Get started\n",
                      "\n",
                      "Click the link below to **download or update** the [okdp-examples](https://github.com/OKDP/okdp-examples) repository directly into your JupyterLab workspace.\n",
                      "\n",
                      "> Tip: If you already cloned it before, this will **pull the latest changes**.\n",
                      "\n",
                      "[âœ… Sync OKDP Examples]({{ $jupyterUrl }}/hub/user-redirect/git-pull?repo=https://github.com/OKDP/okdp-examples&branch=main&urlpath=lab/tree/okdp-examples/notebooks/index.ipynb)\n",
                      "\n",
                      "---\n",
                      "\n",
                      "## ðŸ§­ Whatâ€™s inside the repo\n",
                      "\n",
                      "- **Helm-driven workflows** to download public datasets and upload them to S3 (MinIO)\n",
                      "- **Trino SQL** examples to create external tables and sync partitions\n",
                      "- **Jupyter notebooks** to query Trino (SQLAlchemy + native SQL)\n",
                      "- Optional **Superset** workflows for visualization\n",
                      "\n",
                      "If you get stuck, open the repoâ€™s [README](https://github.com/OKDP/okdp-examples) and follow the step-by-step instructions.\n"
                    ]
                  }
                ],
                "metadata": {
                  "kernelspec": {
                    "display_name": "Python 3 (ipykernel)",
                    "language": "python",
                    "name": "python3"
                  },
                  "language_info": {
                    "codemirror_mode": {
                      "name": "ipython",
                      "version": 3
                    },
                    "file_extension": ".py",
                    "mimetype": "text/x-python",
                    "name": "python",
                    "nbconvert_exporter": "python",
                    "pygments_lexer": "ipython3",
                    "version": "3.12.12"
                  }
                },
                "nbformat": 4,
                "nbformat_minor": 5
              }
          {{- end }}
      
          jupyter_server_config_py:
            mountPath: /etc/jupyter/jupyter_server_config.py
            stringData: |  
              {{- if .Context.jupyter.storage.s3.tls.insecureSkipVerify }}
              import ssl
              import s3fs
              ssl._create_default_https_context = ssl._create_unverified_context
              _s3fs_client_init = s3fs.core.S3FileSystem.__init__
            
              def _patched_init(self, *args, **kwargs):
                # inject client_kwargs.verify=False to disable SSL validation
                kwargs["client_kwargs"] = kwargs.get("client_kwargs", {})
                kwargs["client_kwargs"]["verify"] = False
                return _s3fs_client_init(self, *args, **kwargs)
              
              s3fs.core.S3FileSystem.__init__ = _patched_init
              {{- end }}
      
              c.ServerApp.contents_manager_class = "jupyterfs.MetaManager"
              c.ServerApp.jpserver_extensions = {"jupyterfs.extension": True}
              buckets = ["{{ .Parameters.bucket }}"]
              import os
              c.JupyterFs.resources = [
                {
                  "name": b,
                  "url": f"s3://{b}/",
                  "type": "fsspec",
                  "defaultWritable": True,
                  "use_listings_cache": False,
                  "auth": "none",
                  "kwargs": {
                      "key": os.environ["FS_S3_ACCESS_KEY"],
                      "secret": os.environ["FS_S3_SECRET_KEY"],
                      "client_kwargs": {
                          "endpoint_url": os.environ["FS_S3_ENDPOINT_URL"],
                      }
                  },
                }
                for b in buckets
              ]
        cpu:
          limit: {{ mulf (float64 .Parameters.cpu) 2 }}
          guarantee: {{ .Parameters.cpu }}
        memory:
          limit: {{ mulf (float64 .Parameters.memoryGi) 2 }}G
          guarantee: {{ .Parameters.memoryGi }}G
      
        profileList:
          - display_name: "ðŸª¶ Minimal Python1"
            description: "Lightweight image with only Python 3.12"
            kubespawner_override:
              image: quay.io/okdp/jupyter/minimal-notebook:python-3.12.12-hub-5.4.2-lab-4.5.0
              image_pull_policy: Always
          - display_name: "ðŸ“Š Scientific Python"
            description: "Includes Git, Pandas, NumPy, S3 browser, and Trino SQL support."
            default: true
            kubespawner_override:
              image: quay.io/okdp/jupyter/scipy-notebook:python-3.12.12-hub-5.4.2-lab-4.5.0
              image_pull_policy: Always
          - display_name: "ðŸ“Š Data Science"
            description: "Includes Git, Pandas, NumPy, S3 browser, and Trino SQL support, Matplotlib, R, and Julia"
            kubespawner_override:
              image: quay.io/okdp/jupyter/datascience-notebook:python-3.12.12-hub-5.4.2-lab-4.5.0
              image_pull_policy: Always
          - display_name: "ðŸ”¥ PySpark"
            description: "Apache Spark big data processing"
            kubespawner_override:
              image_pull_policy: Always
              environment:
                PYSPARK_SUBMIT_ARGS: >-
                  --master k8s://https://kubernetes.default.svc.cluster.local
                  --conf spark.submit.deployMode=client
                  --conf spark.driver.host=$(POD_IP)
                  --conf spark.kubernetes.driverEnv.SPARK_USER=$(NB_USER)
                  --conf spark.executorEnv.SPARK_USER=$(NB_USER)
                  --conf spark.kubernetes.container.image=$(SPARK_EXECUTOR_IMAGE)
                  --conf spark.kubernetes.authenticate.ccountName={{ .Context.sparkRBAC.serviceAccount.name }}
                  --conf spark.kubernetes.namespace={{ .Release.spec.targetNamespace }}
                  --conf spark.eventLog.enabled=true
                  --conf spark.eventLog.dir={{ .Parameters.sparkEventsLogDir }}
                  --conf spark.history.fs.logDirectory={{ .Parameters.sparkEventsLogDir }}
                  --conf spark.eventLog.compress=true
                  --conf spark.eventLog.rolling.enabled=true
                  {{- if .Context.jupyter.storage.s3.tls.insecureSkipVerify }}
                  --conf spark.driver.extraJavaOptions="-Dcom.amazonaws.sdk.disableCertChecking=true"
                  --conf spark.executor.extraJavaOptions="-Dcom.amazonaws.sdk.disableCertChecking=true"
                  {{- end }}
                  pyspark-shell
            profile_options:
              image:
                display_name: "Select PySpark kernel version"
                choices:
                  spark344:
                    display_name: "PySpark 3.4.4 / Python 3.11"
                    kubespawner_override:
                      image: quay.io/okdp/jupyter/all-spark-notebook:spark-3.4.4-python-3.11-java-17-scala-2.12
                      image_pull_policy: Always
                      environment:
                        SPARK_EXECUTOR_IMAGE: quay.io/okdp/spark-py:spark-3.4.4-python-3.11-scala-2.12-java-17
                  spark356:
                    display_name: "PySpark 3.5.6 / Python 3.11"
                    default: true
                    kubespawner_override:
                      image: quay.io/okdp/jupyter/all-spark-notebook:spark-3.5.6-python-3.11-java-17-scala-2.12
                      image_pull_policy: Always
                      environment:
                        SPARK_EXECUTOR_IMAGE: quay.io/okdp/spark-py:spark-3.5.6-python-3.11-scala-2.12-java-17
        
        serviceAccountName: {{ .Context.sparkRBAC.serviceAccount.name }}
        storage:
          homeMountPath: "/home/{username}"
          dynamic:
            storageClass: standard
            # Fix PVC naming conflicts by prefixing with release name
            pvcNameTemplate: "{{ .Release.metadata.name }}-claim-{username}{servername}"
            volumeNameTemplate: "{{ .Release.metadata.name }}-volume-{username}{servername}"
          type: dynamic
          extraVolumes:
            - name: {{ .Context.examples.storage.s3.credentialsSecret.name  }}
              secret:
                secretName: {{ .Context.examples.storage.s3.credentialsSecret.name  }}
          extraVolumeMounts:
            - name: {{ .Context.examples.storage.s3.credentialsSecret.name  }}
              mountPath: "/var/run/secrets/examples/s3"
              readOnly: true
        cloudMetadata:
          blockWithIptables: false
        uid: 0
        fsGid: 100
        extraPodConfig:
          automount_service_account_token: true
          terminationGracePeriodSeconds: 120
        networkPolicy:
          enabled: false
      prePuller:
        hook:
          enabled: false
        continuous:
          enabled: false

roles:
  - notebooks
dependencies:
  - ingress
  - storage